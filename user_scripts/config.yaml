# path folder where the wrangler output should be.  if this doesn't exist yet
# it will be created during the wrangler_by_sample step
# e.g. /foo/bar/test_data_wrangled
wrangled_folder: /d/MIPTools_output/test_data_wrangled

# name of the primary table to use from the wrangling step. Can usually be left
# at default of allInfo.tsv.gz
wrangled_file: allInfo.tsv.gz

# path to the sample sheet
# e.g. /foo/bar/test-data/test_data/sample_list.tsv
input_sample_sheet: /d/resources/miptools_test-data/test_data/sample_list.tsv

# path to the directory of fastq files
# e.g. /foo/bar/test-data/test_data/fastq
fastq_dir: /d/resources/miptools_test-data/test_data/fastq

# path to the project resources and species resources directories
# e.g. /foo/bar/test-data/DR1_project_resources
project_resources: /d/resources/miptools_test-data/DR1_project_resources
species_resources: /d/resources/miptools_test-data/pf_species_resources

# path to the sif file you want to use
# e.g. /foo/bar/miptools.sif
miptools_sif: /d/resources/MIPTools_sample_groups.sif

# path to folder where the variant_calling output should go
# e.g. /foo/bar/test_data_vc
variant_calling_folder: "/d/MIPTools_output/test_data_variant"
# If too many CPUs are used in parallel a memory intensive process may cause a crash
# freebayes is a particuarly memory intensive process so it is separate
# e.g. general_cpu_count: 16 and freebayes_cp_count: 8
general_cpu_count: 16
freebayes_cpu_count: 8

# abbreviated name of the species of interest.  Must match a value found
# in the first column of file_locations.tsv (from species_resources directory)
# e.g. pf
species: pf

#only rows from the sample_set column of the sample sheet that are an exact
#match to the sample set listed below will be analyzed. If the samples you want
#to analyze are coming from multiple sample sets, list all sample sets delimited
#by commas with no spaces, e.g. JJJ,MSMT-2021,MSMT-2022 would pull samples that
#have an exact match to JJJ, MSMT-2021, or MSMT-2022 in the sample_set column
sample_set: JJJ

#only rows from the sample sheet that contain exact matches to the probe sets
#listed here (after splitting the probe_set column with commas) will be
#analyzed.
probe_set: DR1

#if you have a very large number of samples that won't run all the way from
#start to finish in one pass, or if you'd like to troubleshoot this pipeline,
#you can have it generate an intermediate output other than the final step.
#Input should be a number. By default, this should be set to 6. Options are:
#1 (extraction of reads for each sample)
#2 (UMI correction for each sample)
#3 (correction for samples that had the wrong sample barcodes assigned)
#4 (haplotype clustering for each sample)
#5 (haplotype clustering for each mip)
#6 (final output table)
output_choice: 6

#memory_mb_per_step applies only when submitting on a slurm cluster. Since in
#our experience slurm submissions slow down analysis, you can leave this at its
#default value.
memory_mb_per_step: 20000

#number of umis to include for each mip/sample combo. This keeps massively over-
#sequenced stuff from bogging down the analysis. 20000 is default, but in
#practice, we haven't extensively tested this feature so recommend setting it to
#a very high number (e.g. 20000000000) to avoid downsampling altogether.
downsample_umi_count: 20000000000

#when downsampling occurs, this random seed allows you to make sure thesame
#random seeds get chosen when re-running a sample (or you could change the
#number to see if results are robust when different random umis are chosen).
#Since we're not recommending downsampling yet, you can leave this value alone.
downsample_seed: 312

#bwa settings go here. No need to edit this unless you'd like to decrease the
#number of threads to use for bwa. bwa runs quickly and is not usually the cause
#of any crashes.
bwa_extra: ['-t', '16']

#leave these at their default values unless you'd like to only analyze
#haplotypes that have a minimum number of UMIs, or that are seen in a minimum
#number of samples, or that account for a minimum fraction of the UMIs that
#exist in any given sample. The recommendation here is to not do any filtering
#at this step (we'd like to see the output data in as 'raw' a format as
#possible) unless you have too many haplotypes for the analysis to finish.
min_haplotype_barcodes: 1
min_haplotype_samples: 1
min_haplotype_sample_fraction: 0.0001

#repool spreadsheet settings. These are for determining which samples to repool
#or recapture, and for determining whether each sample should be repooled or
#recaptured. Current settings indicate that if 95% of the mips in a sample
#(target_coverage_fraction=0.95) hit 10 UMIs per sample (target_coverage_key
#=targets_with_10_barcodes) then this sample doesn't need to be repooled or
#recaptured. Samples that get 10,000 UMIs or more in total (high_barcode_
#threshold=10000) also don't need to be resequenced or repooled. If a sample has
#more than 10 reads per UMI on average (barcode_coverage_threshold=10) then it
#should probably be recaptured with more MIPs, because the same small number of
#UMIs are being sequenced again and again. If the total number of UMIs for a
#sample is below 100 (barcode_count_threshold=100) then recommend recapturing
#(low_coverage_action=Recapture). Samples that have more than the 25th
#percentile of the coverage (of at least 1 UMI per sample (assessment_key=
#'targets_with_1_barcodes')) seen for completed samples (good_coverage_quantile=
#0.25) and yet still aren't complete are marked as 'uneven coverage'. These
#settings only impact the advice that the repool.csv spreadsheet will give you
#and can probably be mostly left alone, except that the best choice for high_
#barcode_threshold will be strongly impacted by the number of MIPs in your project
#design.
high_barcode_threshold: 10000
low_coverage_action: Recapture
target_coverage_count: null
target_coverage_fraction: 0.95
target_coverage_key: targets_with_10_barcodes
barcode_coverage_threshold: 10
barcode_count_threshold: 100
assessment_key: targets_with_1_barcodes
good_coverage_quantile: 0.25


#This block is for variant calling with for freebayes. These are the settings
#that we've found work best for Plasmodium falciparum.
freebayes_settings: ["--pooled-continuous", "--min-alternate-fraction", "0.01",
  "--min-alternate-count", "2", "--haplotype-length", "3",
  "--min-alternate-total", "10", "--use-best-n-alleles", "70",
  "--genotype-qualities", "--gvcf", "--gvcf-dont-use-chunk", "true"]

#This block is for settings for generating final allele tables. 'geneid_to_
#genename' is the location within your project resources folder of a file that
#tells this pipeline which "common names" to assign to each official gene ID.
#'target_aa_annotation' is a file of known targeted amino acid mutations of the
#genome that we'd like freebayes to make calls for even if the regions are not
#mutated. 'target_nt_annotation' is the same thing but for noncoding regions of
#the genome. 'aggregate_nucleotides' controls whether complex nucleotide changes
#that result in the same outcome get lumped together or analyzed separately,
#while 'aggregate_aminoacids' does the same thing for protein-coding mutations.
#'annotate' controls whether the VCF file gets annotated by SNPEff. 'decompose_
#options' is for more granular control of the splitting of complex mutations
#into simple ones and can be left empty for now. If 'aggregate_none' is set to
#'true' then no aggregation across different types of complex mutations will be
#performed. 'annotated_vcf' tells the pipeline whether the input VCF file is
#already annotated with SNPEff, and 'output_prefix' currently needs to be set to
#empty quotes. This function will change the prefixes of the output tables but
#will also cause the snakemake pipeline to error out due to 'missing' the final
#expected output tables with their default names.
geneid_to_genename: /opt/project_resources/geneid_to_genename.tsv
target_aa_annotation: /opt/project_resources/targets.tsv
target_nt_annotation: null
aggregate_nucleotides: true
aggregate_aminoacids: true
annotate: true
decompose_options: []
aggregate_none: true
annotated_vcf: false
output_prefix: ''
min_site_qual: 1
