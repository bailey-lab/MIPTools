Bootstrap: docker
From: amd64/ubuntu:20.04

%post
    # set number of cpus to use in build
    CPU_COUNT=20
    # set build environment
    export DEBIAN_FRONTEND=noninteractive \
        CONDA_DIR=/opt/conda \
        SHELL=/bin/bash \
        LANG=en_US.UTF-8 \
        LANGUAGE=en_US.UTF-8 \
        LC_ALL=en_US.UTF-8 \
        MINICONDA_VERSION=4.8.3
    export PATH=$CONDA_DIR/bin:$PATH

    # install system packages
    apt-get update \
    && apt-get -yq dist-upgrade \
    && apt-get install -yq --no-install-recommends \
    wget \
    bzip2 \
    ca-certificates \
    sudo \
    locales \
    fonts-liberation \
    fonts-dejavu \
    git \
    build-essential \
    gcc \
    openssh-client \
    nano \
    libtbb-dev \
    libz-dev \
    libxrender1 \
    cmake \
    automake \
    autoconf \
    rsync \
    pigz \
    perl-tk \
    less \
    software-properties-common \
    libxext6 \
    libxrender1 \
    ghostscript \
    openjdk-11-jdk \
    liblzma-dev \
    libbz2-dev \
    libssl-dev \
    libcurl4-gnutls-dev \
    alien \
    unzip \
    tree

    # set environment locale
    echo "en_US.UTF-8 UTF-8" >> /etc/locale.gen
    echo "LANG=en_US.UTF-8" > /etc/locale.conf
    echo "LC_ALL=en_US.UTF-8" >> /etc/environment
    echo "LANGUAGE=en_US.UTF-8" >> /etc/environment
    locale-gen en_US.UTF-8
    update-locale LANG=en_US.UTF-8

    # install bcl2fastq, if the file is there
    cd /opt/programs
    unzip bcl2fastq2*.zip || true
    alien bcl2fastq2*.rpm || true
    dpkg -i bcl2fastq2*.deb || true

    # install msa2vcf
    cd /opt/programs
    git clone https://github.com/lindenb/jvarkit.git
    cd jvarkit
    ./gradlew msa2vcf

    # install conda
    cd /tmp && \
        wget --quiet https://repo.continuum.io/miniconda/Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh && \
        echo "d63adf39f2c220950a063e0529d4ff74 *Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh" | md5sum -c - && \
        /bin/bash Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh -f -b -p $CONDA_DIR && \
        rm Miniconda3-py38_${MINICONDA_VERSION}-Linux-x86_64.sh && \
        $CONDA_DIR/bin/conda config --add channels defaults && \
        $CONDA_DIR/bin/conda config --add channels bioconda && \
        $CONDA_DIR/bin/conda config --add channels conda-forge && \
        $CONDA_DIR/bin/conda config --add channels r && \
        $CONDA_DIR/bin/conda config --system --set show_channel_urls true && \
        $CONDA_DIR/bin/conda install --quiet --yes conda="${MINICONDA_VERSION%.*}.*" && \
        conda clean -tipsy

    # install mamba
    conda install mamba -c conda-forge

    # install conda packages using mamba
    mamba install -qy\
      "r-epitools" \
      "r" \
      "rpy2" \
      "r-irkernel" \
      "r-plotly" \
      "r-knitr" \
      "r-shiny" \
      "r-ggplot2" \
      "r-devtools" \
      "r-dplyr" \
      "r-dt" \
      "r-pkgbuild" \
      "gxx_linux-64" \
      "python" \
      "notebook" \
      "jupyter_contrib_nbextensions" \
      "xlrd" \
      "bcftools" \
      "samtools" \
      "vcftools" \
      "htslib" \
      "bwa" \
      "bowtie2" \
      "primer3" \
      "primer3-py" \
      "numpy" \
      "scipy" \
      "biopython" \
      "pysam" \
      "pandas" \
      "matplotlib" \
      "seaborn" \
      "scikit-learn" \
      "scandir" \
      "openpyxl" \
      "simplegeneric" \
      "matplotlib-venn" \
      "tblib" \
      "parallel" \
      "scikit-allel" \
      "bioconductor-dnacopy" \
      "basemap-data-hires" \
      "seqtk=1.3" \
      "gatk4" \
      "freebayes" \
      "lastz" \
      "plotly"

    # install vt variant tool set
    cd /opt/programs
    git clone https://github.com/atks/vt.git
    cd vt
    make -j $CPU_COUNT
    scp vt /opt/bin

    Rscript -e 'devtools::install_github("OJWatson/McCOILR")'

    # install MIPWrangler
    cd /opt/programs
    git clone https://github.com/bailey-lab/MIPWrangler
    cd MIPWrangler
    git checkout v1.2.0
    ./install.sh $CPU_COUNT

    # install elucidator
    cd /opt/programs
    git clone https://github.com/nickjhathaway/elucidator
    cd elucidator
    git checkout develop
    ./install.sh $CPU_COUNT

    # install parasight
    scp /opt/programs/parasight_v7.6/parasight.pl /opt/bin/parasight76.pl

    # add executable flag to executables
    chmod -R +xr /usr/bin
    chmod -R +xr /opt/bin


    # create work and resources directories in /opt
    mkdir /opt/work \
        /opt/project_resources \
        /opt/species_resources \
        /opt/data \
        /opt/analysis \
        /opt/host_species \
        /opt/extras


%files
    programs /opt
    bin /opt
    src /opt
    base_resources/ /opt/resources

%environment
    path=/opt/bin:/opt/conda/bin:/opt/programs/MIPWrangler/bin:
    path=$path/opt/programs/elucidator/bin:/opt/programs/gatk:
    path=$path$PATH
    export PATH=$path
    export XDG_RUNTIME_DIR=""
    export DEBIAN_FRONTEND=noninteractive
    export LANG=en_US.UTF-8
    export LANGUAduGE="en_US.UTF-8"
    export LC_ALL="en_US.UTF-8"

%apprun jupyter
    set -e
    set -u
    nb_port=$(shuf -i 8000-9999 -n 1)
    server_ip=$(hostname -i)
    server_user=$(whoami)@$(hostname -f)
    nb_dir=/opt
    while getopts p:d: OPT; do
        case "$OPT" in
            p)
              nb_port="$OPTARG";;
            d)
              nb_dir="$OPTARG";;
            *)
              echo "Invalid option. Use -p to specify notebook port \
                   -d to specify notebook directory."
        esac
    done
    rsync /opt/resources/*.ipynb /opt/analysis --ignore-existing \
        --ignore-missing-args
    port_fw="Use the following command if you are running this notebook from "
    port_fw=$port_fw"a remote server. Ignore if using a local computer."
    echo $port_fw
    port_fw="ssh -N -f -L localhost:$nb_port:$server_ip:$nb_port $server_user"
    echo $port_fw
    jupyter notebook --notebook-dir=$nb_dir --ip=$server_ip \
            --port=$nb_port --no-browser

%apprun wrangler
    set -e
    set -u
    # set defaults
    cluster_script="runMIPWranglerCurrent.sh"
    server_number=1
    cpu_count=1
    min_capture_length="none"
    stitch_options="none"
    keep_files=""
    while getopts p:l:e:s:w:n:c:x:m:k OPT; do
        case "$OPT" in
            e)
              experiment_id="$OPTARG";;
            l)
              sample_list="$OPTARG";;
            p)
              probe_sets="$OPTARG";;
            s)
              sample_sets="$OPTARG";;
            w)
              cluster_script="$OPTARG";;
            n)
              server_number="$OPTARG";;
            c)
              cpu_count="$OPTARG";;
            x)
              stitch_options="$OPTARG";;
            k)
              keep_files="-k";;

            m)
              min_capture_length="$OPTARG";;

            *)
              echo "Invalid option. Use 'wrangler \
              -e experiment_id -l sample_list.file -p  probe_sets\
              -s sample_sets -w cluster_script -n server_number \
              -c  cpu_count -x stitch_options'  \
              -m min_capture_length [-k]"
        esac
    done
    python /opt/src/generate_wrangler_scripts.py \
    -e $experiment_id -l /opt/analysis/$sample_list \
    -p $probe_sets -s $sample_sets -w $cluster_script -n $server_number \
    -c $cpu_count -x $stitch_options -m $min_capture_length $keep_files
    . /opt/analysis/wrangle.sh

%apprun download
    set -e
    set -u
    while getopts r: opt; do
        case $opt in
            r)  run_id=$OPTARG;;
            ?)  echo "Usage: singularity run --app download \\"
                echo "           -B /path_to_output_dir:/opt/analysis \\"
                echo "           -B /path_to_base_resources:/opt/resources \\"
                echo "            mycontainer.sif -r my_Illumina_run_ID"
                echo "An 'access_token.txt' file with a valid access token is "
                echo "required. It must be present in base_resources directory."
                echo "A data directory where the data will be downloaded to"
                echo "must be mounted to /opt/data."
                exit 1;;
        esac
    done
    echo "Downloading NextSeq run $run_id from BaseSpace."
    echo "Depending on the data size, this can take very long (up to 10 h)"
    echo "It is recommended to run this app in a screen (GNU screen)."
    echo "A message indicating the end of download will be printed when done."
    echo "Check nohup.out file in your output directory for the download log."
    cd /opt/analysis
    nohup python /opt/bin/BaseSpaceRunDownloader_v2.py \
     -r $run_id -a "$(cat /opt/resources/access_token.txt)"
    echo "Download finished."

%apprun demux
    set -e
    set -u
    while getopts s:p: opt; do
        case $opt in
            s)  sample_list=$OPTARG;;
            p)  platform=$OPTARG;;
            ?)  echo "Usage: singularity run --app demux \\"
                echo "           -B /path_to_run_dir:/opt/data \\"
                echo "           -B /path_to_output_dir:/opt/analysis \\"
                echo "           -B /path_to_base_resources:/opt/resources \\"
                echo "            mycontainer.sif -s sample_list_file \\"
                echo "            -p sequencing_platform (nextseq or miseq) \\"
                echo "The sample list file must be present in the output"
                echo "directory mounted to /opt/analysis."
                exit 1;;
        esac
    done
    # create a sample sheet for demultiplexing
    cd /opt/src
    template_dir="/opt/resources/templates/sample_sheet_templates/"
    platform_template="$platform"_sample_sheet_template.csv
    template="$template_dir$platform_template"
    bc_dict="/opt/resources/barcode_dict.json"
    output_dir="/opt/analysis"
    sample_list="/opt/analysis/$sample_list"
    python -c 'import mip_functions as mip; mip.generate_sample_sheet(
        "'"$sample_list"'", "'"$bc_dict"'", "'"$template"'", "'"$platform"'",
        "'"$output_dir"'")'
    # cd to where bcl files are.
    cd /opt/data
    # create a fastq directory for saving fastqs
    mkdir -p /opt/analysis/fastq
    # increase limit of open number of files.
    ulimit -Sn $(ulimit -Hn)
    nohup bcl2fastq -o /opt/analysis/fastq \
        --sample-sheet /opt/analysis/SampleSheet.csv \
        --no-lane-splitting

%apprun demux_qc
    set -e
    set -u
    while getopts p: opt; do
        case $opt in
            p)  platform=$OPTARG;;
            ?)  echo "Usage: singularity run --app demux_qc\\"
                echo "           -B /path_to_base_resources:/opt/resources \\"
                echo "           -B /path_to_fastq_dir:/opt/analysis "
                echo "            mycontainer.sif -p sequencing_platform"
                exit 1;;
        esac
    done
    python /opt/src/demux_qc.py -p $platform
