{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1996a7-7832-484b-8fe3-8e39e9cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "import sys\n",
    "sys.path.append(\"/opt/src\")\n",
    "import mip_functions as mip\n",
    "import probe_summary_generator\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.lines import Line2D\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import allel\n",
    "wdir = \"/opt/analysis/\"\n",
    "data_dir = \"/opt/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b220bad",
   "metadata": {},
   "source": [
    "# Calling genotypes, prevalences and filtering data\n",
    "The original vcf file created by freebayes contain the genotypes determined by the program itself. In addition, genotype values for aggregated and non-aggregated nucleotides and aminoacids are also available as *_genotypes_table.csv files as described above.  \n",
    "\n",
    "However, the default parameters generating the vcf file are not very strict. In this part of the analysis we will apply various filters to the count tables and generate genotype calls based on those filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb239b1",
   "metadata": {},
   "source": [
    "### Chose which tables to analyse\n",
    "Select the type of data to analyse. Make sure the count file is matching the coverage file. e.g. alternate_XX_table and coverage_XX_table, XX must be the same value (AA, AN or nothing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba304e",
   "metadata": {},
   "source": [
    "#### Example cell\n",
    "```python\n",
    "mutation_count_file = \"/opt/analysis/alternate_AA_table.csv\"\n",
    "mutation_coverage_file = \"/opt/analysis/coverage_AA_table.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "\n",
    "mutation_count_file = \"/opt/analysis/alternate_AA_table.csv\"\n",
    "mutation_coverage_file = \"/opt/analysis/coverage_AA_table.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "import pandas as pd\n",
    "mutation_counts = pd.read_csv(mutation_count_file,\n",
    "                              header=list(range(6)),\n",
    "                              index_col=0)\n",
    "mutation_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d630d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN\n",
    "mutation_coverage = pd.read_csv(mutation_coverage_file,\n",
    "                                index_col=0,\n",
    "                                header=list(range(6)))\n",
    "mutation_coverage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d6741",
   "metadata": {},
   "source": [
    "### Set your filters   \n",
    "1.  **min_coverage**: how many UMIs are needed to for a genomic position for a sample to reliably call genotypes. If we set min_coverage = 10, any locus within a sample that is covered below this threshold will have an NA genotype.\n",
    "2.  **min_count**: if a genomic position have enough coverage, how many UMIs supporting an ALT allele call is needed for a reliable call. If we set min_count = 2, any mutation with an  call that has less than 2 UMIs supporting the ALT call will revert to REF.\n",
    "3.  **min_freq**: a minimum within sample allele frequency threshold to consider a variant valid. If set to 0.01, for example, a variant locus in a sample that is at 0.005 frequency for the ALT allele within the sample, the locus would be called REF, if the within sample AF is between 0.01 and 0.99, it would be considered HET, and if > 0.99, it would be homozygous ALT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f680c",
   "metadata": {},
   "source": [
    "#### Example cell\n",
    "```python\n",
    "# filter mutation counts for minimum count parameter\n",
    "# by setting counts to zero if it is below threshold\n",
    "min_count = 2\n",
    "# filter loci without enough coverage by setting\n",
    "# coverage to zero if it is below threshold\n",
    "min_coverage = 10\n",
    "# call genotypes using the minimum within sample\n",
    "# allele frequency\n",
    "min_freq = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUT \n",
    "\n",
    "# filter mutation counts for minimum count parameter\n",
    "# by setting counts to zero if it is below threshold\n",
    "min_count = 2\n",
    "# filter loci without enough coverage by setting\n",
    "# coverage to zero if it is below threshold\n",
    "min_coverage = 10\n",
    "# call genotypes using the minimum within sample\n",
    "# allele frequency\n",
    "min_freq = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "\n",
    "# import the PCA module which has genotype calling and\n",
    "# filtering functions \n",
    "import PCA\n",
    "\n",
    "gt_calls = PCA.call_genotypes(mutation_counts, mutation_coverage,\n",
    "                              min_count, min_coverage, min_freq)\n",
    "gt_calls.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbe8fd",
   "metadata": {},
   "source": [
    "### What are the dataframes generated by call_genotypes function and how  are they generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab506a25",
   "metadata": {},
   "source": [
    "**filtered_mutation_counts**: take the mutation_counts table, if a cell's value is below *min_count*, reset that cell's value to zero, otherwise leave as is.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2649811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "filtered_mutation_counts = gt_calls[\"filtered_mutation_counts\"]\n",
    "filtered_mutation_counts.to_csv(os.path.join(\n",
    "        wdir, \"filtered_alternate_AA_table.csv\"))\n",
    "filtered_mutation_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de8bb0",
   "metadata": {},
   "source": [
    "**filtered_mutation_coverage**: take the mutation_coverage table, if a cell's value is below *min_coverage*, reset that cell's value to zero, otherwise leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "filtered_mutation_coverage = gt_calls[\"filtered_mutation_coverage\"]\n",
    "filtered_mutation_coverage.to_csv(os.path.join(\n",
    "        wdir, \"filtered_coverage_AA_table.csv\"))\n",
    "filtered_mutation_coverage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaafa91",
   "metadata": {},
   "source": [
    "**wsaf**: divide *filtered_mutation_counts* table by *filtered_mutation_coverage* table, yielding within sample allele frequencies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc97d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "freq = gt_calls[\"wsaf\"]\n",
    "freq.to_csv(os.path.join(\n",
    "        wdir, \"within_sample_allele_frequencies.csv\"))\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e976119",
   "metadata": {},
   "source": [
    "**genotypes**: take the *wsaf* table, if a cell's value is less than *min_freq* set the genotype value to 0 (homozygous wild type); if the cell's value is more than (*1 - min_freq*) set the genotype value to 2 (homozygous mutant), if the cell's value is between *min_freq* and (*1 - min_freq*) set the genotype value to 1 (heterozygous/mixed).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4efc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "genotypes = gt_calls[\"genotypes\"]\n",
    "genotypes.to_csv(os.path.join(\n",
    "        wdir, \"filtered_genotypes_table.csv\"))\n",
    "genotypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a17d7d",
   "metadata": {},
   "source": [
    "**prevalences**: take the *genotypes* table, if a cell's value is 2, reset its value to 1; otherwise leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "prevalences = gt_calls[\"prevalences\"]\n",
    "prevalences.to_csv(os.path.join(wdir, \"prevalences_input_table.csv\"))\n",
    "prevalences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ce785",
   "metadata": {},
   "source": [
    "## Filter genotypes / prevalences\n",
    "It is generally a good idea to do some basic noise removal once the genotypes are created. Some suggestions are provided here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c1259e",
   "metadata": {},
   "source": [
    "### Filter variants that are always at low WSAF\n",
    "If a variant is only seen at a low frequency within samples, it is a good indication that it could be just noise. Here we will set a number of samples and minimum WSAF threshold to remove such noise.\n",
    "\n",
    "```python\n",
    "num_samples_wsaf = 2\n",
    "min_wsaf = 0.5\n",
    "wsaf_filter = ((freq > min_wsaf).sum()) >= num_samples_wsaf\n",
    "```\n",
    "\n",
    "The above options will keep the variants that are in at > 0.5 WSAF in at least 2 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "num_samples_wsaf = 2\n",
    "min_wsaf = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsaf_filter = ((freq > min_wsaf).sum()) >= num_samples_wsaf\n",
    "print((\"{} of {} variants will remain after the wsaf filter\").format(\n",
    "    wsaf_filter.sum(), freq.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797b30b",
   "metadata": {},
   "source": [
    "### Filter variants that are observed with low UMI counts\n",
    "If a variant is only supported by a low number of UMIs across the entire sample set, it is another indication of noise.\n",
    "\n",
    "```python\n",
    "num_samples_umi = 2\n",
    "min_umi = 3\n",
    "umi_filter = ((filtered_mutation_counts >= min_umi).sum()) > num_samples_umi\n",
    "```\n",
    "\n",
    "The above options will keep the variants that are supported by at least 3 UMIs in at least 2 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "num_samples_umi = 2\n",
    "min_umi = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "umi_filter = ((filtered_mutation_counts >= min_umi).sum()) > num_samples_umi\n",
    "print((\"{} of {} variants will remain after the UMI filter\").format(\n",
    "    umi_filter.sum(), freq.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80589b",
   "metadata": {},
   "source": [
    "### Keep variants that were targeted\n",
    "In most projects there are a number of variants that we would like to report, even if they are not seen in the sample set. We would like to stop those variants from being removed by the above filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN\n",
    "targ = freq.columns.get_level_values(\"Targeted\") == \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11625ca6",
   "metadata": {},
   "source": [
    "### Combine filters\n",
    "Keep the variants that are either targeted or passing filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_mask = targ | (wsaf_filter & umi_filter)\n",
    "print((\"{} variants will remain in the final call set.\\n\"\n",
    "       \"{} variants were targeted and will be kept; and {} will be removed by \"\n",
    "       \"the combined UMI and WSAF filters.\").format(\n",
    "    variant_mask.sum(), targ.sum(), (wsaf_filter & umi_filter).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be875d3a",
   "metadata": {},
   "source": [
    "## Filter data tables with the combined filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_genotypes = genotypes.loc[:, variant_mask]\n",
    "filtered_genotypes.to_csv(os.path.join(wdir, \"final_filtered_genotypes.csv\"))\n",
    "filtered_genotypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_prevalences = prevalences.loc[:, variant_mask]\n",
    "filtered_prevalences.to_csv(os.path.join(wdir, \"final_filtered_prevalences_input_table.csv\"))\n",
    "filtered_prevalences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4b571-2402-4766-a1cf-5baecd7879e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalences_input_table = '/opt/analysis/prevalences_input_table.csv'\n",
    "metadata_file = '/opt/prevalence_metadata/PRX-00_metadata.csv'\n",
    "UMI_suffix = '-PRX-00-1'\n",
    "output_file = open('/opt/analysis/test_new_prevalence.csv','w')\n",
    "\n",
    "mutations = [\n",
    "\"crt-Cys72Ser\",\n",
    "\"crt-Val73Leu\",\n",
    "\"crt-Met74Ile\",\n",
    "\"crt-Asn75Glu\",\n",
    "\"crt-Lys76Thr\",\n",
    "\"crt-Asn326Ser\",\n",
    "\"crt-Ile356Thr\",\n",
    "\"dhfr-ts-Asn51Ile\",\n",
    "\"dhfr-ts-Cys59Arg\",\n",
    "\"dhfr-ts-Ser108Asn\",\n",
    "\"dhfr-ts-Ser108Thr\",\n",
    "\"dhfr-ts-Ile164Leu\",\n",
    "\"dhps-Ala437Gly\",\n",
    "\"dhps-Ala581Gly\",\n",
    "\"dhps-Ala613Ser\",\n",
    "\"dhps-Ala613Thr\",\n",
    "\"dhps-Ile431Val\",\n",
    "\"dhps-Lys540Glu\",\n",
    "\"dhps-Ser436Ala\",\n",
    "\"dhps-Ser436Phe\",\n",
    "\"k13-Ala675Val\",\n",
    "\"k13-Arg539Thr\",\n",
    "\"k13-Arg561His\",\n",
    "\"k13-Arg622Ile\",\n",
    "\"k13-Cys469Phe\",\n",
    "\"k13-Cys469Tyr\",\n",
    "\"k13-Cys580Tyr\",\n",
    "\"k13-Pro441Leu\",\n",
    "\"k13-Tyr493His\",\n",
    "\"k13-Val568Gly\",\n",
    "\"mdr1-Asn1042Asp\",\n",
    "\"mdr1-Asn86Phe\",\n",
    "\"mdr1-Asn86Tyr\",\n",
    "\"mdr1-Asp1246Tyr\",\n",
    "\"mdr1-Ser1034Cys\",\n",
    "\"mdr1-Tyr184Phe\"]\n",
    "def create_site_dict(metadata_file):\n",
    "\tsite_dict = {}\n",
    "\tfor line in open (metadata_file):\n",
    "\t\tif 'Sites' not in line:\n",
    "\t\t\tline = line.strip().split(',')\n",
    "\t\t\tsample = line[1]+UMI_suffix\n",
    "\t\t\tsite = line[0]\n",
    "\t\t\tsite_dict[sample] = site\n",
    "\treturn site_dict\n",
    "\n",
    "# {site:mutation_name}\n",
    "\n",
    "def get_counts(prevalences_input_table, site_dict):\n",
    "\tcount_dict = {}\n",
    "\tcount_dict['overall'] = {}\n",
    "\tbase, top = 0, 0\n",
    "\tfor line_number, line in enumerate(open(prevalences_input_table, 'r')):\n",
    "\t\tif \"Mutation Name\" in line:\n",
    "\t\t\tmutation_dict = dict(enumerate(line.strip().split(',')[1:]))\n",
    "\t\t\t# need to print an error message if two mutations have the same name\n",
    "\t\tif line_number >= 6:\n",
    "\t\t\tline = line.strip().split(',')\n",
    "\t\t\tsample = line[0]\n",
    "\t\t\tif sample in site_dict:\n",
    "\t\t\t\tsite = site_dict[sample]\n",
    "\t\t\t\tif site not in count_dict:\n",
    "\t\t\t\t\tcount_dict[site] = {}\n",
    "\t\t\t\tfor tally_number, tally in enumerate(line[1:]):\n",
    "\t\t\t\t\t# mutation_name = tally_number\n",
    "\t\t\t\t\tif tally == '':\n",
    "\t\t\t\t\t\tif tally_number not in count_dict[site]:\n",
    "\t\t\t\t\t\t\tcount_dict[site][tally_number] = [0, 0]\n",
    "\t\t\t\t\t\tif tally_number not in count_dict['overall']:\n",
    "\t\t\t\t\t\t\tcount_dict['overall'][tally_number] = [0, 0]\n",
    "\t\t\t\t\tif tally == '0.0':\n",
    "\t\t\t\t\t\tif tally_number not in count_dict[site]:\n",
    "\t\t\t\t\t\t\tcount_dict[site][tally_number] = [0, 1]\n",
    "\t\t\t\t\t\tcount_dict[site][tally_number][1] += 1\n",
    "\t\t\t\t\t\tif tally_number not in count_dict['overall']:\n",
    "\t\t\t\t\t\t\tcount_dict['overall'][tally_number] = [0, 1]\n",
    "\t\t\t\t\t\tcount_dict['overall'][tally_number][1] += 1\n",
    "\t\t\t\t\tif tally == '1.0':\n",
    "\t\t\t\t\t\tif tally_number not in count_dict[site]:\n",
    "\t\t\t\t\t\t\tcount_dict[site][tally_number] = [1, 1]\n",
    "\t\t\t\t\t\tcount_dict[site][tally_number][1] += 1\n",
    "\t\t\t\t\t\tcount_dict[site][tally_number][0] += 1\n",
    "\t\t\t\t\t\tif tally_number not in count_dict['overall']:\n",
    "\t\t\t\t\t\t\tcount_dict['overall'][tally_number] = [1, 1]\n",
    "\t\t\t\t\t\tcount_dict['overall'][tally_number][1] += 1\n",
    "\t\t\t\t\t\tcount_dict['overall'][tally_number][0] += 1\n",
    "\treturn count_dict, mutation_dict\n",
    "\n",
    "site_dict = create_site_dict(metadata_file)\n",
    "count_dict, mutation_dict = get_counts(prevalences_input_table, site_dict)\n",
    "# print(count_dict)\n",
    "\n",
    "output_file.write('Sites')\n",
    "sites = list(count_dict.keys())\n",
    "sites.remove('overall')\n",
    "sites.sort()\n",
    "for column_number in mutation_dict:\n",
    "\tif mutation_dict[column_number] in mutations:\n",
    "\t\toutput_file.write('\\t'+mutation_dict[column_number])\n",
    "for site in sites:\n",
    "\toutput_file.write('\\n'+site)\n",
    "\tfor column_number in count_dict[site]:\n",
    "\t\tif mutation_dict[column_number] in mutations:\n",
    "\t\t\talt = count_dict[site][column_number][0]\n",
    "\t\t\tcov = count_dict[site][column_number][1]\n",
    "\t\t\tif alt == 0:\n",
    "\t\t\t\tprevalence = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tprevalence = alt/cov\n",
    "\t\t\toutput_file.write(f\"\\t{prevalence} ({alt}/{cov})\")\n",
    "output_file.write('\\n'+'overall')\n",
    "for column_number in count_dict['overall']:\n",
    "\tif mutation_dict[column_number] in mutations:\n",
    "\t\talt = count_dict['overall'][column_number][0]\n",
    "\t\tcov = count_dict['overall'][column_number][1]\n",
    "\t\tif alt == 0:\n",
    "\t\t\tprevalence = 0\n",
    "\t\telse:\n",
    "\t\t\tprevalence = alt/cov\n",
    "\t\toutput_file.write(f\"\\t{prevalence} ({alt}/{cov})\")\n",
    "prevalences_output = pd.read_csv('/opt/analysis/test_new_prevalence.csv',sep='\\t', index_col=0)\n",
    "prevalences_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28766ce4-261b-49b3-a6aa-3e2385a5e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "########### USER INPUT #################\n",
    "prevalence_summary_file_name='/opt/analysis/test_new_prevalence.csv'\n",
    "region_of_interest='uganda'\n",
    "\n",
    "# load the inputs\n",
    "region_dict = {'uganda':['uganda-with-regions.geojson',5, {\"lat\": 1.3733, \"lon\": 32.2903}],\n",
    "               'tanzania':[['tanzania-with-regions.geojson',4, {\"lat\": -6.3690, \"lon\": 34.8888}]]}\n",
    "region_list=[\n",
    "    ('uganda',),\n",
    "    ('tanzania',)\n",
    "]\n",
    "prevalence_summary_df = pd.read_csv(prevalence_summary_file_name, sep='\\t')\n",
    "\n",
    "# identify columns that are variants not headers\n",
    "variant_columns=prevalence_summary_df.columns.difference(['Sites'])\n",
    "\n",
    "# get a list of every variant from the dataframe and convert prevalence values to floats\n",
    "variant_list = []\n",
    "for column in variant_columns:\n",
    "    prevalence_summary_df[column]=[float(x.split()[0]) for x in prevalence_summary_df[column]]\n",
    "    variant_list.append(column)\n",
    "\n",
    "def display_choropleth(variant):\n",
    "    json_file = json.load(open('/opt/prevalence_metadata/'+region_dict[region_of_interest][0]))\n",
    "    fig = px.choropleth_mapbox(prevalence_summary_df, \n",
    "                                geojson=json_file, \n",
    "                                locations='Sites', \n",
    "                                color=variant,\n",
    "                                color_continuous_scale=\"reds\",\n",
    "                                mapbox_style=\"carto-positron\",\n",
    "                                featureidkey=\"properties.name\",\n",
    "                                zoom=region_dict[region_of_interest][1], \n",
    "                                center = region_dict[region_of_interest][2],\n",
    "                                labels={'Sites':'Site'},\n",
    "                                range_color=(0,1),\n",
    "    )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(height=600)\n",
    "    return fig\n",
    "\n",
    "interact(display_choropleth, variant=variant_list);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
